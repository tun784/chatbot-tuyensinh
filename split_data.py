import os
import re

def clean_text_for_splitting(text):
    text = text.replace("ğŸ”°", "").replace("ğŸ”¶", "").replace("ğŸ”¸", "")
    text = text.replace('\t', ' ')
    text = re.sub(r'\n\s*\n', '\n\n', text) 
    text = re.sub(r'\s*\n\s*', '\n', text)  
    text = re.sub(r'[ \t]+', ' ', text)     
    return text.strip()

def split_into_chunks_hybrid(original_text, max_words_per_chunk=300, overlap_words=50):
    cleaned_text = clean_text_for_splitting(original_text)
    paragraphs = cleaned_text.split('\n\n') # TÃ¡ch theo Ä‘oáº¡n Ä‘Ã£ Ä‘Æ°á»£c chuáº©n hÃ³a
    final_chunks = []
    
    for para_text in paragraphs:
        para_text = para_text.strip()
        if not para_text: continue

        para_text_single_spaced = re.sub(r'\s+', ' ', para_text) # Chuáº©n hÃ³a space trong Ä‘oáº¡n Ä‘á»ƒ Ä‘áº¿m tá»«
        words_in_para = para_text_single_spaced.split()
        
        if len(words_in_para) <= max_words_per_chunk:
            # Náº¿u Ä‘oáº¡n Ä‘á»§ ngáº¯n, dÃ¹ng text gá»‘c cá»§a Ä‘oáº¡n (cÃ³ thá»ƒ cÃ²n \n Ä‘Æ¡n)
            final_chunks.append(para_text) 
        else:
            # Náº¿u Ä‘oáº¡n quÃ¡ dÃ i, chia theo tá»« (words_in_para Ä‘Ã£ lÃ  1 dÃ²ng)
            step = max_words_per_chunk - overlap_words
            if step <= 0: step = max_words_per_chunk // 2 if max_words_per_chunk > 1 else 1
            for i in range(0, len(words_in_para), step):
                chunk_words = words_in_para[i : i + max_words_per_chunk]
                if not chunk_words: continue
                final_chunks.append(" ".join(chunk_words)) 
    return final_chunks

def read_all_txt_files(data_dir="data"):
    all_chunks_with_meta = []
    print(f"Äang Ä‘á»c file tá»« thÆ° má»¥c: {data_dir}")
    files = sorted(os.listdir(data_dir)) # Sáº¯p xáº¿p Ä‘á»ƒ cÃ³ thá»© tá»± nháº¥t quÃ¡n
    for filename in files:
        if filename.endswith(".txt"):
            filepath = os.path.join(data_dir, filename)
            try:
                with open(filepath, "r", encoding="utf-8") as f:
                    original_text = f.read()
                current_file_chunks_text = split_into_chunks_hybrid(original_text)
                for chunk_text_content in current_file_chunks_text:
                    # Quan trá»ng: Chuáº©n hÃ³a láº§n cuá»‘i má»—i chunk thÃ nh 1 dÃ²ng cho embedding
                    text_for_embedding_and_rag = re.sub(r'\s+', ' ', chunk_text_content).strip()
                    if text_for_embedding_and_rag: # Chá»‰ thÃªm náº¿u chunk khÃ´ng rá»—ng sau khi strip
                        all_chunks_with_meta.append({
                            "filename": filename,
                            "text": text_for_embedding_and_rag 
                        })
                print(f"  - ÄÃ£ xá»­ lÃ½ {filename} -> {len(current_file_chunks_text)} chunks Ä‘Æ°á»£c thÃªm vÃ o.")
            except Exception as e:
                print(f"  - Lá»—i khi Ä‘á»c hoáº·c xá»­ lÃ½ file {filename}: {e}")
    return all_chunks_with_meta

if __name__ == "__main__":
    chunks_list = read_all_txt_files(data_dir="data") 
    print(f"\nÄÃ£ tÃ¡ch thÃ nh cÃ´ng tá»•ng cá»™ng {len(chunks_list)} chunks.")