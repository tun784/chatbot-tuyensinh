# split_data.py (PhiÃªn báº£n má»›i Ä‘á»c JSON vÃ  chia chunk thÃ´ng minh hÆ¡n)
import os
import json
import re

def clean_text_for_splitting(text):
    """LÃ m sáº¡ch cÆ¡ báº£n trÆ°á»›c khi chia: xÃ³a icon, chuáº©n hÃ³a space/newline."""
    # Thay tháº¿ cÃ¡c icon Ä‘Ã£ biáº¿t báº±ng má»™t dáº¥u cÃ¡ch Ä‘á»ƒ trÃ¡nh dÃ­nh tá»«
    text = text.replace("ğŸ”°", " ").replace("ğŸ”¶", " ").replace("ğŸ”¸", " ")
    # Loáº¡i bá» cÃ¡c emoji khÃ¡c báº±ng regex, thay báº±ng dáº¥u cÃ¡ch
    emoji_pattern = re.compile(
        "["
        "\U0001F600-\U0001F64F"  # emoticons
        "\U0001F300-\U0001F5FF"  # symbols & pictographs
        "\U0001F680-\U0001F6FF"  # transport & map symbols
        "\U0001F700-\U0001F77F"  # alchemical symbols
        "\U0001F780-\U0001F7FF"  # Geometric Shapes Extended
        "\U0001F800-\U0001F8FF"  # Supplemental Arrows-C
        "\U0001F900-\U0001F9FF"  # Supplemental Symbols and Pictographs
        "\U0001FA00-\U0001FA6F"  # Chess Symbols
        "\U0001FA70-\U0001FAFF"  # Symbols and Pictographs Extended-A
        "\U00002700-\U000027BF"  # Dingbats
        # Bá» cÃ¡c dáº£i unicode rá»™ng cÃ³ thá»ƒ xÃ³a chá»¯ Viá»‡t náº¿u khÃ´ng cáº©n tháº­n
        # "\U000024C2-\U0001F251"
        # "\U00002600-\U000026FF"  # Miscellaneous Symbols
        "]+", flags=re.UNICODE
    )
    text = emoji_pattern.sub(r' ', text)

    text = text.replace('\t', ' ')
    # Chuáº©n hÃ³a nhiá»u dÃ²ng trá»‘ng thÃ nh 2 newline (Ä‘á»ƒ Ä‘Ã¡nh dáº¥u Ä‘oáº¡n)
    text = re.sub(r'\n\s*\n', '\n\n', text) 
    # Chuáº©n hÃ³a cÃ¡c newline Ä‘Æ¡n láº» (xÃ³a space xung quanh)
    text = re.sub(r'\s*\n\s*', '\n', text)  
    # Chuáº©n hÃ³a nhiá»u space thÃ nh 1 space (khÃ´ng áº£nh hÆ°á»Ÿng \n)
    text = re.sub(r'[ \t]+', ' ', text)     
    return text.strip()

def split_text_into_chunks(original_text, filename="unknown", max_words_per_chunk=200, overlap_words=40):
    """
    Chia vÄƒn báº£n thÃ nh cÃ¡c chunk. Æ¯u tiÃªn chia theo Ä‘oáº¡n (Ä‘Ã¡nh dáº¥u báº±ng '\n\n').
    Náº¿u Ä‘oáº¡n quÃ¡ dÃ i, sáº½ chia Ä‘oáº¡n Ä‘Ã³ theo sá»‘ tá»«.
    CÃ¡c chunk cuá»‘i cÃ¹ng sáº½ Ä‘Æ°á»£c chuáº©n hÃ³a thÃ nh má»™t dÃ²ng duy nháº¥t.
    """
    cleaned_text_with_paragraphs = clean_text_for_splitting(original_text)
    # paragraphs = cleaned_text_with_paragraphs.split('\n\n') 
    paragraphs = original_text.split('\n\n') 
    
    final_chunks_text_only = []
    
    for para_text in paragraphs:
        para_text_stripped = para_text.strip()
        if not para_text_stripped:
            continue

        # Äá»ƒ Ä‘áº¿m tá»«, chuáº©n hÃ³a Ä‘oáº¡n vÄƒn thÃ nh má»™t dÃ²ng duy nháº¥t cÃ¡c tá»«
        para_text_single_spaced_for_word_count = re.sub(r'\s+', ' ', para_text_stripped)
        words_in_para = para_text_single_spaced_for_word_count.split()
        
        # Äiá»u chá»‰nh max_words cho cÃ¡c file quan trá»ng
        current_max_words = max_words_per_chunk
        if "gioi-thieu-chung.txt" in filename or "cac-nganh-dao-tao.txt" in filename:
            current_max_words = 150 # Chunk nhá» hÆ¡n cho file chung
        elif "thu-tuc-nhap-hoc.txt" in filename:
            current_max_words = 180

        if len(words_in_para) <= current_max_words:
            # Náº¿u Ä‘oáº¡n Ä‘á»§ ngáº¯n, chuáº©n hÃ³a thÃ nh 1 dÃ²ng vÃ  thÃªm vÃ o
            final_chunks_text_only.append(re.sub(r'\s+', ' ', para_text_stripped).strip())
        else:
            # Náº¿u Ä‘oáº¡n quÃ¡ dÃ i, chia theo tá»« (sá»­ dá»¥ng words_in_para Ä‘Ã£ lÃ  1 dÃ²ng)
            step = current_max_words - overlap_words
            if step <= 0: step = current_max_words // 2 if current_max_words > 1 else 1

            for i in range(0, len(words_in_para), step):
                chunk_words = words_in_para[i : i + current_max_words]
                if not chunk_words: continue
                final_chunks_text_only.append(" ".join(chunk_words))
            
    return final_chunks_text_only

def process_json_data(json_file_path="data_collection.json"):
    """
    Äá»c dá»¯ liá»‡u tá»« file JSON, lÃ m sáº¡ch vÃ  tÃ¡ch thÃ nh chunks.
    """
    all_chunks_with_meta = []
    print(f"Äang Ä‘á»c vÃ  xá»­ lÃ½ file JSON: {json_file_path}")
    
    try:
        with open(json_file_path, "r", encoding="utf-8") as f:
            data_from_json = json.load(f)
    except FileNotFoundError:
        print(f"Lá»—i: KhÃ´ng tÃ¬m tháº¥y file {json_file_path}. HÃ£y cháº¡y convert_txt_to_json.py trÆ°á»›c.")
        return []
    except json.JSONDecodeError:
        print(f"Lá»—i: File {json_file_path} khÃ´ng chá»©a JSON há»£p lá»‡.")
        return []

    found_gioi_thieu_chung = False
    for item in data_from_json:
        filename = item.get("filename", "unknown_file.txt")
        original_text = item.get("text_content", "")

        if filename == "gioi-thieu-chung.txt":
            found_gioi_thieu_chung = True

        if not original_text:
            print(f"  - Bá» qua file {filename} vÃ¬ khÃ´ng cÃ³ ná»™i dung.")
            continue
            
        # Chia text cá»§a file hiá»‡n táº¡i thÃ nh cÃ¡c chunks
        current_file_text_chunks = split_text_into_chunks(original_text, filename=filename)
        
        chunks_added_this_file = 0
        for chunk_text in current_file_text_chunks:
            if chunk_text: # Chá»‰ thÃªm náº¿u chunk khÃ´ng rá»—ng sau khi strip
                all_chunks_with_meta.append({
                    "filename": filename,
                    "text": chunk_text  # chunk_text Ä‘Ã£ Ä‘Æ°á»£c chuáº©n hÃ³a thÃ nh 1 dÃ²ng
                })
                chunks_added_this_file += 1
        print(f"  - ÄÃ£ xá»­ lÃ½ {filename} -> {chunks_added_this_file} chunks Ä‘Æ°á»£c thÃªm vÃ o.")

    if not found_gioi_thieu_chung:
        print("Cáº¢NH BÃO QUAN TRá»ŒNG: KhÃ´ng tÃ¬m tháº¥y 'gioi-thieu-chung.txt' trong file JSON.")
        print("CÃ¡c cÃ¢u há»i vá» Ä‘á»‹a chá»‰, há»c phÃ­ cÃ³ thá»ƒ khÃ´ng Ä‘Æ°á»£c tráº£ lá»i chÃ­nh xÃ¡c.")
        
    return all_chunks_with_meta

if __name__ == "__main__":
    # BÆ°á»›c 1: Cháº¡y convert_txt_to_json.py Ä‘á»ƒ táº¡o data_collection.json (náº¿u chÆ°a cÃ³ hoáº·c muá»‘n cáº­p nháº­t)
    # convert_txt_to_json(data_dir="data", output_json_file="data_collection.json") # Bá» comment náº¿u muá»‘n cháº¡y luÃ´n á»Ÿ Ä‘Ã¢y

    # BÆ°á»›c 2: Äá»c tá»« data_collection.json vÃ  táº¡o chunks
    chunks_list = process_json_data(json_file_path="data_collection.json") 
    print(f"\nÄÃ£ tÃ¡ch thÃ nh cÃ´ng tá»•ng cá»™ng {len(chunks_list)} chunks tá»« file JSON.")

    # In ra thá»­ vÃ i chunk Ä‘áº§u tiÃªn tá»« gioi-thieu-chung.txt Ä‘á»ƒ kiá»ƒm tra
    print("\n--- Sample chunks from gioi-thieu-chung.txt (náº¿u cÃ³) ---")
    count = 0
    for chk in chunks_list:
        if chk["filename"] == "gioi-thieu-chung.txt":
            print(f"\nChunk {count+1} (tá»« gioi-thieu-chung.txt):")
            print(f"Text (first 300 chars): {chk['text'][:300]}...")
            count += 1
            if count >= 5: # In ra 5 chunk Ä‘áº§u tiÃªn cá»§a file nÃ y
                break
    if count == 0:
        print("KhÃ´ng tÃ¬m tháº¥y chunk nÃ o tá»« gioi-thieu-chung.txt Ä‘á»ƒ in máº«u (cÃ³ thá»ƒ file khÃ´ng tá»“n táº¡i trong JSON hoáº·c khÃ´ng cÃ³ chunk nÃ o Ä‘Æ°á»£c táº¡o).")